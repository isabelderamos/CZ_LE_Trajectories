### loading libraries
#library(dplyr)
library(tidyverse)
# INSTALL LIBRARIES ----
library(dplyr)
library(tidyverse)
library(stringr)
library(purrr)
library(classInt)
library(grid)
library(gridExtra)
library(scales)
library(multcomp)
library(RColorBrewer)
library(scales)
# INSTALL LIBRARIES ----
library(tidyverse)
library(classInt)
library(grid)
library(gridExtra)
library(scales)
library(multcomp)
library(RColorBrewer)
library(scales)
library(ggpubr)
#install.packages("devtools")
#library(devtools)
#install.packages("rstan", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
#install.packages("remotes")
#remotes::install_github("timriffe/DemoTools")
#install.packages("DemoTools")
library(DemoTools)
library(RColorBrewer)
#remotes::install_github("coolbutuseless/ggpattern")
#install.packages("ggpattern")
library(ggpattern)
library(moments)
#install.packages("biscale")
library(biscale)
library(sf)
library(cowplot)
#devtools::install_github("ropenscilabs/rnaturalearth")
library(rnaturalearth)
# install.packages("rnaturalearthdata")
library(rnaturalearthdata)
library(sp)
# install.packages("spdep")
library(spdep)
library(rgeoda)
# install.packages("pals")
library(pals)
#~~~~ (1) ggplot helpers ~~~~#
### prep for generating plots ###
select<-dplyr::select
fontsize<-16
isabel_theme <-theme_bw()+
theme(axis.text=element_text(color="black", size=fontsize),
axis.title=element_text(color="black", size=fontsize, face="bold"),
plot.title=element_text(color="black", size=fontsize, face="bold", hjust = 0.5),
strip.background=element_blank(),
strip.text=element_text(color="black", size=fontsize, face="bold"),
legend.text=element_text(color="black", size=fontsize),
legend.title=element_text(color="black", size=fontsize, face="bold"))
map_theme <- isabel_theme+
theme(axis.line=element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank(),
axis.ticks=element_blank(),
axis.title.x=element_blank(),
axis.title.y=element_blank(),
panel.background = element_rect(fill = "lightblue1"),
panel.border=element_blank(),
panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
plot.background = element_rect(fill = "lightblue1"),
plot.margin = unit(c(0,0,0,0), "cm"),
plot.tag = element_text(face="bold", size=40),
legend.text = element_text(size=24),
legend.background = element_rect(fill='transparent'), #transparent legend bg
legend.box.background = element_rect(fill='transparent')) #transparent legend panel
moran_colors<-c("lightgray", "dodgerblue4", "firebrick", "black", "white")
# bivariat3 palette
cols<-brewer.divdiv(n=9)
# change middle color for a darker gray
cols[5]<-"gray50"
cols[6]<- "skyblue3"
get_legend<-function(plot){
grobs<-ggplotGrob(plot)$grobs
legend <- grobs[[which(sapply(grobs, function(x) x$name) == "guide-box")]]
return(legend)
}
## (2.A) CAMARDA'S FUNCTIONS FOR LIFETABLES, LIFE EXPECTANCY
# see https://sites.google.com/site/carlogiovannicamarda/r-stuff/life-expectancy-confidence-interval
## lifetable() calculates life expectancy
## CIex() calculates 95% CI
source('LifeTableFUN.R')
## (2.B) LE_LV FUNCTION
le_lv<-function(.x, .y, age_num, sex="B"){
## .x -> the data with one race and CBSA
# example: .x<- dta %>% filter(gender=="Men", cbsa=="10100", year5%in%'2015-2019')
## .y -> a dataframe wtih whichever CBSA or race category you are looking at
# using lifetable() function from Camarda to create lifetable
lt <- lifetable(x=.x$age_5yr_group, Nx=.x$pop_denom, Dx=.x$count, sex=sex, ax=NULL)
# using CIex function from Camarda to obtain confidence intervals
ci_dta <- CIex(x=.x$age_5yr_group, Nx=.x$pop_denom, Dx=.x$count, sex=sex, ax=NULL, which.x=age_num, ns=1000, level=0.95)
# adding variables needed to calculate lifespan variation
lt <- lt %>% mutate(xbar=NA_real_,
noname=NA_real_,
v=NA_real_,
sd=NA_real_)
lt <- lt %>% mutate(xbar=x+ax,
noname=case_when(
x==0 ~ dx/lx*(xbar-ex)^2,
x!=0 ~ {
lx_forlv <- lt %>% filter(x==0) %>% pull(lx)
ex_forlv <- lt %>% filter(x==0) %>% pull(ex)
dx/lx_forlv*(xbar-ex_forlv)^2}),
v=rev(cumsum(rev(noname))),
sd=sqrt(v))
# extracting LE
le <- lt %>% filter(x==age_num) %>% pull(ex)
# extracting 95% CI
ci <- ci_dta %>% pluck("CIex") %>% unname()
# extracting LV
lv_sd <- lt %>% filter(x==age_num) %>% pull(sd) # this is standard deviation
lv_cv <- lv_sd/le # this is CoV = coefficient of variance (standard deviation / LE)
# building df that summarizes results
data.frame(le=le,
lci=ci[1],
uci=ci[2],
lv_sd=lv_sd,
lv_cv=lv_cv)
}
get_bivarite <- function(.x, .y, gender_mw="Men", yr_35="year3", cbsa_cz="cbsa") {
dta <- results_cbsa_cz %>% filter(gender%in%gender_mw, year_type%in%yr_35, type%in%cbsa_cz)
if(yr_35=="year3") {
## CATEGORIZATION OF LE'S, USING BASELINE (1990-1992) LE USING TERTILES
le_bin <- dta %>% pull(le) %>% sort() %>%
quantile(probs=seq(0,1,1/3))
## CATEGORIZATION OF GAINS/LOSSES USING TERTILES
dif_bin <- dta %>% select(year, id, gender, le) %>%
group_by(year, id, gender) %>%
spread(year, le) %>%
mutate(abs_dif=`2017-2019`-`1990-1992`,
rel_dif=`2017-2019`/`1990-1992`) %>%
ungroup() %>%
gather("year", "le", 3:12) %>%
pull(abs_dif) %>%
sort() %>%
quantile(probs=seq(0,1,1/3))
df <- dta %>% select(year, id, gender, le) %>%
group_by(year, id, gender) %>%
spread(year, le) %>%
mutate(abs_dif=`2017-2019`-`1990-1992`,
rel_dif=`2017-2019`/`1990-1992`) %>%
ungroup() %>%
gather("year", "le", 3:12) %>%
filter(year%in%"1990-1992") %>% # using 1990-1992 as baseline
mutate(cat=case_when(
year%in%"1990-1992" & le>=le_bin[3] & abs_dif>dif_bin[3] ~ 9,
year%in%"1990-1992" & le>=le_bin[3] & between(abs_dif, dif_bin[2], dif_bin[3]) ~ 8,
year%in%"1990-1992" & le>=le_bin[3] &  abs_dif< dif_bin[2] ~ 7,
year%in%"1990-1992" & between(le, le_bin[2], le_bin[3]) & abs_dif>dif_bin[3] ~ 6,
year%in%"1990-1992" & between(le, le_bin[2], le_bin[3]) & between(abs_dif, dif_bin[2], dif_bin[3]) ~ 5,
year%in%"1990-1992" & between(le, le_bin[2], le_bin[3]) & abs_dif< dif_bin[2] ~ 4,
year%in%"1990-1992" & le<le_bin[2] & abs_dif>dif_bin[3] ~ 3,
year%in%"1990-1992" & le<le_bin[2] & between(abs_dif, dif_bin[2], dif_bin[3]) ~ 2,
year%in%"1990-1992" & le<le_bin[2] & abs_dif< dif_bin[2] ~ 1))
## breakdown: abs_dif = difference from most recent period (2017-2019) to oldest (1990-1992)
# 9 = high LE, most increase since 1990-1992
# 8 = high LE, moderate increase since 1990-1992
# 7 = high LE, most decrease since 1990-1992
# 6 = moderate LE, most increase since 1990-1992
# 5 = moderate LE, moderate increase since 1990-1992
# 4 = moderate LE, most decrease since 1990-1992
# 3 = low LE, most increase since 1990-1992
# 2 = low LE, moderate increase since 1990-1992
# 1 = low LE, most decrease since 1990-1992
df <- bi_class(df, x=le, y=abs_dif, style="quantile", dim=3)
print(df)
} else if (yr_35=="year5") {
## CATEGORIZATION OF LE'S, USING BASELINE (1990-1992) LE USING TERTILES
le_bin <- dta %>% pull(le) %>% sort() %>%
quantile(probs=seq(0,1,1/3))
dif_bin <- dta %>% select(year, id, gender, le) %>%
group_by(year, id, gender) %>%
spread(year, le) %>%
mutate(abs_dif=`2015-2019`-`1990-1994`,
rel_dif=`2015-2019`/`1990-1994`) %>%
ungroup() %>%
gather("year", "le", 3:8) %>%
pull(abs_dif) %>%
sort() %>%
quantile(probs=seq(0,1,1/3))
df <- dta %>% select(year, id, gender, le) %>%
group_by(year, id, gender) %>%
spread(year, le) %>%
mutate(abs_dif=`2015-2019`-`1990-1994`,
rel_dif=`2015-2019`/`1990-1994`) %>%
ungroup() %>%
gather("year", "le", 3:8) %>%
filter(year%in%"1990-1994") %>% # using 1990-1992 as baseline
mutate(cat=case_when(
year%in%"1990-1994" & le>=le_bin[3] & abs_dif>dif_bin[3] ~ 9,
year%in%"1990-1994" & le>=le_bin[3] & between(abs_dif, dif_bin[2], dif_bin[3]) ~ 8,
year%in%"1990-1994" & le>=le_bin[3] &  abs_dif< dif_bin[2] ~ 7,
year%in%"1990-1994" & between(le, le_bin[2], le_bin[3]) & abs_dif>dif_bin[3] ~ 6,
year%in%"1990-1994" & between(le, le_bin[2], le_bin[3]) & between(abs_dif, dif_bin[2], dif_bin[3]) ~ 5,
year%in%"1990-1994" & between(le, le_bin[2], le_bin[3]) & abs_dif< dif_bin[2] ~ 4,
year%in%"1990-1994" & le<le_bin[2] & abs_dif>dif_bin[3] ~ 3,
year%in%"1990-1994" & le<le_bin[2] & between(abs_dif, dif_bin[2], dif_bin[3]) ~ 2,
year%in%"1990-1994" & le<le_bin[2] & abs_dif< dif_bin[2] ~ 1))
df <- bi_class(df, x=le, y=abs_dif, style="quantile", dim=3)
print(df)
}
}
#~~~~ (3) loading in master datafile (see LE_data_prep.R) ~~~~#
load('1990_2019_cbsa_mortality.rdata')
library(readxl)
library(tidyvers)
dta<-read_excel("~/Downloads/sportsref_download.xlsx")
dta
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2)
dta
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G)
library(tidyverse)
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G)
head(dta)
table(dta$Pos)
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G,
pos2=case_when(
grepl("OLB", pos) ~ "OLB",
grepl("LB", pos) ~ "LB",
T ~ "other"
))
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G,
pos2=case_when(
grepl("OLB", Pos) ~ "OLB",
grepl("LB", Pos) ~ "LB",
T ~ "other"
))
table(dta$Pos, dta$pos2)
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G,
pos2=case_when(
grepl("OLB", Pos) ~ "OLB",
grepl("LB", Pos) ~ "LB",
T ~ NA
))
table(dta$Pos, dta$pos2)
unique(dta$Pos)
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G,
pos2=case_when(
grepl("OLB", Pos) ~ "OLB",
grepl("LB", Pos) ~ "LB",
grepl("CB", Pos) ~ "CB",
grepl("DT", Pos) ~ "DT",
T ~ NA
))
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G,
pos2=case_when(
grepl("OLB", Pos) ~ "OLB",
grepl("LB", Pos) ~ "LB",
grepl("CB", Pos) ~ "CB",
grepl("DT", Pos) ~ "DT",
T ~ Pos
))
unique(dta$Pos)
unique(dta$pos2)
dta %>% filter(is.na(pos2))
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G,
pos2=case_when(
grepl("OLB", Pos) ~ "OLB",
grepl("LB", Pos) ~ "LB",
grepl("CB", Pos) ~ "CB",
grepl("DT", Pos) ~ "DT",
grepl("DE", Pos) ~ "DE",
T ~ Pos
))
dta %>% group_by(pos2) %>%
summarise(avg=mean(avg))
dta %>% group_by(pos2) %>%
summarise(avg=mean(avg, na.rm=T))
dta %>% group_by(pos2) %>%
summarise(avg=mean(avg, na.rm=T)) %>%
arrange(desc(avg))
dta %>% filter(pos2=="LT")
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G,
pos2=case_when(
grepl("OLB", Pos) ~ "OLB",
grepl("LB", Pos) ~ "LB",
grepl("CB", Pos) ~ "CB",
grepl("DT", Pos) ~ "DT",
grepl("DE", Pos) ~ "DE",
Pos%in%c("RT", "LT", "OT") ~ "OT",
T ~ Pos
))
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G,
pos2=case_when(
grepl("OLB", Pos) ~ "OLB",
grepl("LB", Pos) ~ "LB",
grepl("CB", Pos) ~ "CB",
grepl("DT", Pos) ~ "DT",
grepl("DE", Pos) ~ "DE",
Pos%in%c("RT", "LT", "OT") ~ "OT",
Pos%in%c("RG", "LG", "OG") ~ "OG",
T ~ Pos
))
dta %>% group_by(pos2) %>%
summarise(avg=mean(avg, na.rm=T)) %>%
arrange(desc(avg))
dta %>% group_by(pos2) %>%
summarise(avg=mean(avg, na.rm=T)) %>%
arrange(desc(avg)) %>% print(n=50)
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G,
pos2=case_when(
grepl("OLB", Pos) ~ "OLB",
grepl("LB", Pos) ~ "LB",
grepl("CB", Pos) ~ "CB",
grepl("DT", Pos) ~ "DT",
grepl("DE", Pos) ~ "DE",
Pos%in%c("RT", "LT", "OT") ~ "OT",
Pos%in%c("RG", "LG", "OG") ~ "OG",
pos2%in%c("OT", "OG") ~ "OL",
T ~ Pos
))
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G,
pos2=case_when(
grepl("OLB", Pos) ~ "OLB",
grepl("LB", Pos) ~ "LB",
grepl("CB", Pos) ~ "CB",
grepl("DT", Pos) ~ "DT",
grepl("DE", Pos) ~ "DE",
Pos%in%c("RT", "LT", "OT") ~ "OT",
Pos%in%c("RG", "LG", "OG") ~ "OG",
Pos%in%c("RT", "LT", "OT", "RG", "LG", "OG") ~ "OL",
T ~ Pos
))
dta %>% group_by(pos2) %>%
summarise(avg=mean(avg, na.rm=T)) %>%
arrange(desc(avg)) %>% print(n=50)
dta %>% filter(pos2=="NT")
dta<-read_excel("~/Downloads/sportsref_download.xlsx", sheet=2) %>%
mutate(avg=AV/G,
pos2=case_when(
grepl("OLB", Pos) ~ "OLB",
grepl("LB", Pos) ~ "LB",
grepl("CB", Pos) ~ "CB",
grepl("DT", Pos) ~ "DT",
grepl("DE", Pos) ~ "DE",
Pos%in%c("NT", "DT") ~ "DT",
Pos%in%c("RT", "LT", "OT") ~ "OT",
Pos%in%c("RG", "LG", "OG") ~ "OG",
Pos%in%c("RT", "LT", "OT", "RG", "LG", "OG") ~ "OL",
T ~ Pos
))
dta %>% group_by(pos2) %>%
summarise(avg=mean(avg, na.rm=T)) %>%
arrange(desc(avg)) %>% print(n=50)
library(tidyverse)
dta<-read_csv("~/Downloads/Altmetric - Research Outputs - Drexel University - 2025-01-09.csv")
head(dta)
View(dta)
dta$`Badge URL`
dta$`Details Page URL`
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details URL`, fixed=T))
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T))
test$id
View(test)
head(test$id)
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id)
head(test)
head(dta)
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title)
head(test)
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title)
test
test$authors
str_split_1(test$authors, pattern = ";")
dta
dta<-read_csv("~/Downloads/Altmetric - Research Outputs - Drexel University - 2025-01-09.csv") %>%
mutate(rank=row_number())
dta$rank
dta %>% filter(grepl("Lazo, Mariana", `Authors at my Institution`))
dta %>% filter(grepl("Lazo, Mariana", `Authors at my Institution`)) %>% select(rank)
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(rank, altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title) %>%
separate(col=`Authors at my Institution`, sep=";")
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(rank, altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title) %>%
separate(col=authors, sep=";")
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(rank, altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title) %>%
separate(col=authors, sep=";", into="author")
head(test)
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(rank, altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title) %>%
separate(col=authors, sep=";", into=author)
?separate
test$author
?regexpr
grep(";", test$author)
grep(";", test$authors)
test$author
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(rank, altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title)
grep(";", test$authors)
gregexpr(";", test$authors)
str_count(test$authors, ";")
table(str_count(test$authors, ";"))
paste0("author", 1:17)
separate(col=authors, sep=";", into=paste0("author", 1:17), fill="right")
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(rank, altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title) %>%
separate(col=authors, sep=";", into=paste0("author", 1:17), fill="right")
head(test)
View(test)
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(rank, altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title) %>%
separate(col=authors, sep=";", into=paste0("author", 1:17), fill="right") %>%
pivot_longer(cols=-c(rank, altmetric, id, title))
head(test)
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(rank, altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title) %>%
separate(col=authors, sep=";", into=paste0("author", 1:17), fill="right") %>%
pivot_longer(cols=-c(rank, altmetric, id, title)) %>%
filter(!is.na(value))
head(test)
test %>% group_by(value) %>%
summarise(altmetric=sum(altmetric))
test %>% group_by(value) %>%
summarise(altmetric=sum(altmetric)) %>%
arrange(desc(altmetric))
test %>% group_by(value) %>%
summarise(altmetric=sum(altmetric)) %>%
arrange(desc(altmetric)) %>%
print(n=50)
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(rank, altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title) %>%
separate(col=authors, sep=";", into=paste0("author", 1:17), fill="right") %>%
pivot_longer(cols=-c(rank, altmetric, id, title)) %>%
mutate(value=sub("^ ", "", value))
test<-dta %>%
mutate(id=sub("https://www.altmetric.com/details/", "", `Details Page URL`, fixed=T)) %>%
select(rank, altmetric=`Altmetric Attention Score`,
authors=`Authors at my Institution`,
id, title=Title) %>%
separate(col=authors, sep=";", into=paste0("author", 1:17), fill="right") %>%
pivot_longer(cols=-c(rank, altmetric, id, title)) %>%
mutate(value=sub("^ ", "", value)) %>%
filter(!is.na(value))
test %>% group_by(value) %>%
summarise(altmetric=sum(altmetric)) %>%
arrange(desc(altmetric)) %>%
print(n=50)
# INSTALL LIBRARIES ----
library(tidyverse)
dta<-read_csv("~/DOwnloads/IHME_USA_LE_COUNTY_RACE_ETHN_2000_2019_LT_2015_2019 (1)/IHME_USA_LE_COUNTY_RACE_ETHN_2000_2019_LT_2015_BOTH_Y2022M06D16.CSV")
head(dta)
View(dta)
